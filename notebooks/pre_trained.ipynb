{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15200755127104026535\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1493781708\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1268612039573125787\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#check using system GPU for processing and declaring system/GPU parameters\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# configure tensorflow before fitting model\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.Session(config=tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing directory for flow_from_directory method\n",
    "os.chdir('C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 120 classes.\n",
      "Found 2400 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 120\n",
    "batch_size = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=15, shear_range=0.1, channel_shift_range=20,\n",
    "                                    width_shift_range=0.1,  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True,\n",
    "                                    fill_mode='nearest', rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('validation', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('test', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras.utils\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.bestaugmented.pre_trained.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 14,776,248\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "# Load the VGG model\n",
    "# choosing VG166 architecture initially as my hand-built models with 3x3 filters perform the best and generally is more popular\n",
    "\n",
    "vgg16_base = Sequential()\n",
    "vgg16_base.add(VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                pooling='avg'))\n",
    "vgg16_base.add(Dense(num_classes, activation='softmax'))\n",
    "vgg16_base.layers[0].trainable = False\n",
    "\n",
    "# compile\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "vgg16_base.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(vgg16_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 382s 478ms/step - loss: 5.0060 - acc: 0.0078 - val_loss: 4.9803 - val_acc: 0.0092\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 380s 475ms/step - loss: 4.9684 - acc: 0.0075 - val_loss: 4.9534 - val_acc: 0.0092\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 382s 477ms/step - loss: 4.9437 - acc: 0.0086 - val_loss: 4.9312 - val_acc: 0.0104\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 379s 474ms/step - loss: 4.9236 - acc: 0.0078 - val_loss: 4.9120 - val_acc: 0.0108\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 385s 481ms/step - loss: 4.9071 - acc: 0.0082 - val_loss: 4.8955 - val_acc: 0.0117\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 379s 474ms/step - loss: 4.8909 - acc: 0.0089 - val_loss: 4.8810 - val_acc: 0.0121\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 379s 474ms/step - loss: 4.8763 - acc: 0.0081 - val_loss: 4.8680 - val_acc: 0.0113\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 379s 474ms/step - loss: 4.8646 - acc: 0.0086 - val_loss: 4.8566 - val_acc: 0.0121\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 379s 474ms/step - loss: 4.8543 - acc: 0.0100 - val_loss: 4.8463 - val_acc: 0.0121\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 380s 475ms/step - loss: 4.8440 - acc: 0.0095 - val_loss: 4.8369 - val_acc: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a902e8160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_base.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=800, \n",
    "                    epochs=10, \n",
    "                    validation_steps=200,\n",
    "                    callbacks=[early_stopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_base.save('vgg16_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "base_scores = vgg16_base.evaluate_generator(test_generator, steps=25, max_queue_size=10)\n",
    "print(\"Accuracy: %.2f%%\" % (base_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 15,040,952\n",
      "Trainable params: 325,240\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, input_shape=input_shape)\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# train only the top layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 337s 421ms/step - loss: 5.1689 - acc: 0.0075 - val_loss: 4.8430 - val_acc: 0.0108\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 335s 419ms/step - loss: 5.0327 - acc: 0.0075 - val_loss: 4.8252 - val_acc: 0.0104\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 339s 424ms/step - loss: 4.9732 - acc: 0.0079 - val_loss: 4.8169 - val_acc: 0.0092\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 336s 420ms/step - loss: 4.9408 - acc: 0.0095 - val_loss: 4.8082 - val_acc: 0.0117\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 336s 420ms/step - loss: 4.9290 - acc: 0.0074 - val_loss: 4.8038 - val_acc: 0.0088\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 338s 422ms/step - loss: 4.9110 - acc: 0.0096 - val_loss: 4.7982 - val_acc: 0.0138\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 336s 421ms/step - loss: 4.8971 - acc: 0.0080 - val_loss: 4.7976 - val_acc: 0.0108\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 338s 422ms/step - loss: 4.8944 - acc: 0.0078 - val_loss: 4.7948 - val_acc: 0.0071\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 339s 423ms/step - loss: 4.8800 - acc: 0.0081 - val_loss: 4.7925 - val_acc: 0.0096\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 336s 420ms/step - loss: 4.8783 - acc: 0.0096 - val_loss: 4.7922 - val_acc: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27ffe4241d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=800, \n",
    "                    epochs=10, \n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to load data\n",
    "\n",
    "def load_array(fname):\n",
    "    return np.load(open(fname,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in labels and data (as tensors)\n",
    "\n",
    "train_labels=load_array('train_labels.npy')\n",
    "valid_labels=load_array('valid_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor=load_array('train_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_Input(X):\n",
    "    minimum=0\n",
    "    maximum=255\n",
    "    X-minimum/(maximum-minimum)\n",
    "    return X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor=Normalize_Input(train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tensor=load_array('valid_dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tensor=Normalize_Input(valid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 120\n",
    "batch_size = 12\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1)\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# note to self... perhaps the imagedatagenerator parameters I had before were root cause of low accuracy...\n",
    "\n",
    "train_generator = train_datagen.flow(x=train_tensor, y=train_labels, batch_size=batch_size, shuffle=False, seed=16)\n",
    "validation_generator = validation_datagen.flow(x=valid_tensor, y=valid_labels, batch_size=batch_size, shuffle=False, seed=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 14,776,248\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vgg16_v2 = Sequential()\n",
    "vgg16_v2.add(VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                pooling='avg'))\n",
    "vgg16_v2.add(Dense(num_classes, activation='softmax'))\n",
    "vgg16_v2.layers[0].trainable = False\n",
    "\n",
    "# compile\n",
    "vgg16_v2.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "print(vgg16_v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 386s 483ms/step - loss: 13.9315 - acc: 0.0296 - val_loss: 13.1307 - val_acc: 0.0708\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 13.13068, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 386s 482ms/step - loss: 11.3126 - acc: 0.1309 - val_loss: 9.9514 - val_acc: 0.2108\n",
      "\n",
      "Epoch 00002: val_loss improved from 13.13068 to 9.95136, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 387s 484ms/step - loss: 9.6743 - acc: 0.2218 - val_loss: 9.1440 - val_acc: 0.2646\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.95136 to 9.14405, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 384s 480ms/step - loss: 8.4376 - acc: 0.3030 - val_loss: 8.3636 - val_acc: 0.3133\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.14405 to 8.36364, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 386s 483ms/step - loss: 7.9997 - acc: 0.3332 - val_loss: 8.3630 - val_acc: 0.3338\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.36364 to 8.36296, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 387s 483ms/step - loss: 7.3681 - acc: 0.3749 - val_loss: 8.0681 - val_acc: 0.3325\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.36296 to 8.06811, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 385s 481ms/step - loss: 6.7841 - acc: 0.4144 - val_loss: 7.5575 - val_acc: 0.3708\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.06811 to 7.55747, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 384s 480ms/step - loss: 6.5639 - acc: 0.4357 - val_loss: 7.3884 - val_acc: 0.3825\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.55747 to 7.38839, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 384s 479ms/step - loss: 6.2370 - acc: 0.4576 - val_loss: 7.1941 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.38839 to 7.19414, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 383s 479ms/step - loss: 6.0018 - acc: 0.4850 - val_loss: 7.1987 - val_acc: 0.4150\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277104137b8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_v2.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=800, \n",
    "                    epochs=10, \n",
    "                    callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 385s 482ms/step - loss: 5.0574 - acc: 0.5710 - val_loss: 6.5399 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00001: val_loss improved from 6.56802 to 6.53987, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 384s 480ms/step - loss: 5.0060 - acc: 0.5788 - val_loss: 6.7529 - val_acc: 0.4517\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 385s 482ms/step - loss: 4.8536 - acc: 0.5948 - val_loss: 6.8956 - val_acc: 0.4446\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277104bb390>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another round of training\n",
    "\n",
    "vgg16_v2.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=800, \n",
    "                    epochs=10, \n",
    "                    callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 262s 545ms/step - loss: 4.8157 - acc: 0.6049 - val_loss: 6.5087 - val_acc: 0.4596\n",
      "\n",
      "Epoch 00001: val_loss improved from 6.53987 to 6.50873, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 263s 548ms/step - loss: 4.7754 - acc: 0.5866 - val_loss: 6.5720 - val_acc: 0.4642\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 263s 547ms/step - loss: 4.8430 - acc: 0.5951 - val_loss: 6.4419 - val_acc: 0.4683\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.50873 to 6.44187, saving model to saved_models/weights.bestaugmented.pre_trained.hdf5\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 261s 544ms/step - loss: 4.4866 - acc: 0.6300 - val_loss: 6.6533 - val_acc: 0.4608\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 263s 548ms/step - loss: 4.9115 - acc: 0.5936 - val_loss: 6.8625 - val_acc: 0.4458\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277104bb5c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another round of training, increase batch size\n",
    "\n",
    "batch_size=20\n",
    "vgg16_v2.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=480, \n",
    "                    epochs=10, \n",
    "                    callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 264s 549ms/step - loss: 4.6897 - acc: 0.6092 - val_loss: 6.8537 - val_acc: 0.4517\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 262s 547ms/step - loss: 4.6515 - acc: 0.6104 - val_loss: 6.5844 - val_acc: 0.4763\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 261s 545ms/step - loss: 4.6084 - acc: 0.6220 - val_loss: 6.5401 - val_acc: 0.4712\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 262s 545ms/step - loss: 4.4628 - acc: 0.6340 - val_loss: 6.6814 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 263s 548ms/step - loss: 4.6663 - acc: 0.6248 - val_loss: 6.5071 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 262s 545ms/step - loss: 4.6263 - acc: 0.6293 - val_loss: 6.8582 - val_acc: 0.4504\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 262s 546ms/step - loss: 4.1777 - acc: 0.6411 - val_loss: 6.4672 - val_acc: 0.4750\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 262s 547ms/step - loss: 4.2557 - acc: 0.6568 - val_loss: 6.6339 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 263s 548ms/step - loss: 4.3869 - acc: 0.6483 - val_loss: 6.6299 - val_acc: 0.4729\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x277101cb630>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another round of training, maintain batch size\n",
    "\n",
    "batch_size=20\n",
    "vgg16_v2.fit_generator(train_generator, \n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=480, \n",
    "                    epochs=10, \n",
    "                    callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now seems that model is overfitting to the training data.  No additional fitting is needed.\n",
    "vgg16_v2.save('saved_models/vgg16_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
