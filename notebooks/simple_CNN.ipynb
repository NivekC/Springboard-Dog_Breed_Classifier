{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17132357235513740450\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1493781708\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 18400566845976949322\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#check using system GPU for processing and declaring system/GPU parameters\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# configure tensorflow before fitting model\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "sess = tf.Session(config=tf_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare ImageDataGenerator and flow_from_directory vars\n",
    "batch_size=10\n",
    "num_classes = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing directory for flow_from_directory method\n",
    "os.chdir('C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain train and test labels\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#y_train_rough = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "\n",
    "#y_test = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\test_list.mat''')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "files = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['file_list']\n",
    "labels = [item for label in labels for item in label] #this is flattening a list of lists, because for some reason ever label is stored as a list\n",
    "files = [item for file in files for item in file]\n",
    "df = pd.DataFrame({'labels':labels, 'files':files})\n",
    "train, validate = train_test_split(df, test_size = 0.2, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['files']\n",
    "y_train = to_categorical(train['labels'])\n",
    "X_val = validate['files']\n",
    "y_val = to_categorical(validate['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 images belonging to 120 classes.\n",
      "Found 2400 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15, shear_range=0.1, channel_shift_range=20,\n",
    "                                    width_shift_range=0.1,  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True,\n",
    "                                    fill_mode='nearest', rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=25)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('validation', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=25)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('test', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_validation = []\\ny_train = []\\n\\nfor i in range(120):\\n    i = i*100\\n    \\n    #begin_index = train_full_list[i::100]\\n    #end_index = train_full_list[i+100::100]\\n    \\n    slice = y_train_rough[i:i+100,]\\n    y_train.append(slice[:80])\\n    y_validation.append(slice[80:])\\n\\ny_train = np.concatenate(y_train, axis=0)\\ny_validation = np.concatenate(y_validation, axis=0)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain validation labels\n",
    "# no longer used, utilizing sklearn's train_test_split function\n",
    "\n",
    "'''\n",
    "y_validation = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(120):\n",
    "    i = i*100\n",
    "    \n",
    "    #begin_index = train_full_list[i::100]\n",
    "    #end_index = train_full_list[i+100::100]\n",
    "    \n",
    "    slice = y_train_rough[i:i+100,]\n",
    "    y_train.append(slice[:80])\n",
    "    y_validation.append(slice[80:])\n",
    "\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "y_validation = np.concatenate(y_validation, axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a simple CNN to start\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras.utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          65600     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 251,128\n",
      "Trainable params: 251,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224, 3)\n",
    "\n",
    "# create the model\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Flatten())\n",
    "\n",
    "base_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model.add(Dropout(0.2))\n",
    "base_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 158s 526ms/step - loss: 4.7910 - acc: 0.0075 - val_loss: 4.7881 - val_acc: 0.0079\n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 4.7896 - acc: 0.0088 - val_loss: 4.7874 - val_acc: 0.0096\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 152s 507ms/step - loss: 4.7915 - acc: 0.0088 - val_loss: 4.7869 - val_acc: 0.0083\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 153s 508ms/step - loss: 4.7880 - acc: 0.0088 - val_loss: 4.7870 - val_acc: 0.0083\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 154s 513ms/step - loss: 4.7886 - acc: 0.0083 - val_loss: 4.7866 - val_acc: 0.0071\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 158s 526ms/step - loss: 4.7872 - acc: 0.0089 - val_loss: 4.7862 - val_acc: 0.0096\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 155s 516ms/step - loss: 4.7890 - acc: 0.0092 - val_loss: 4.7861 - val_acc: 0.0096\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 154s 515ms/step - loss: 4.7859 - acc: 0.0111 - val_loss: 4.7856 - val_acc: 0.0108\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7885 - acc: 0.0105 - val_loss: 4.7854 - val_acc: 0.0121\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7877 - acc: 0.0079 - val_loss: 4.7854 - val_acc: 0.0117\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 160s 534ms/step - loss: 4.7866 - acc: 0.0092 - val_loss: 4.7850 - val_acc: 0.0100\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 162s 539ms/step - loss: 4.7856 - acc: 0.0120 - val_loss: 4.7846 - val_acc: 0.0096\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 159s 530ms/step - loss: 4.7869 - acc: 0.0095 - val_loss: 4.7841 - val_acc: 0.0083\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 158s 525ms/step - loss: 4.7857 - acc: 0.0109 - val_loss: 4.7834 - val_acc: 0.0100\n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 156s 522ms/step - loss: 4.7857 - acc: 0.0085 - val_loss: 4.7832 - val_acc: 0.0121\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 157s 522ms/step - loss: 4.7845 - acc: 0.0139 - val_loss: 4.7825 - val_acc: 0.0137\n",
      "Epoch 17/25\n",
      "300/300 [==============================] - 160s 534ms/step - loss: 4.7856 - acc: 0.0105 - val_loss: 4.7815 - val_acc: 0.0129\n",
      "Epoch 18/25\n",
      "300/300 [==============================] - 159s 531ms/step - loss: 4.7844 - acc: 0.0125 - val_loss: 4.7809 - val_acc: 0.0112\n",
      "Epoch 19/25\n",
      "300/300 [==============================] - 158s 528ms/step - loss: 4.7823 - acc: 0.0115 - val_loss: 4.7801 - val_acc: 0.0117\n",
      "Epoch 20/25\n",
      "300/300 [==============================] - 157s 525ms/step - loss: 4.7836 - acc: 0.0104 - val_loss: 4.7792 - val_acc: 0.0154\n",
      "Epoch 21/25\n",
      "300/300 [==============================] - 156s 521ms/step - loss: 4.7823 - acc: 0.0129 - val_loss: 4.7773 - val_acc: 0.0146\n",
      "Epoch 22/25\n",
      "300/300 [==============================] - 159s 529ms/step - loss: 4.7787 - acc: 0.0133 - val_loss: 4.7764 - val_acc: 0.0146\n",
      "Epoch 23/25\n",
      "300/300 [==============================] - 180s 601ms/step - loss: 4.7788 - acc: 0.0119 - val_loss: 4.7743 - val_acc: 0.0150\n",
      "Epoch 24/25\n",
      "300/300 [==============================] - 221s 738ms/step - loss: 4.7771 - acc: 0.0140 - val_loss: 4.7721 - val_acc: 0.0133\n",
      "Epoch 25/25\n",
      "300/300 [==============================] - 184s 612ms/step - loss: 4.7757 - acc: 0.0124 - val_loss: 4.7696 - val_acc: 0.0142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d10da1c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit the simple CNN using flow from directory \n",
    "\n",
    "base_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save('base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 1,442,104\n",
      "Trainable params: 1,442,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# tweak base model... decrease first covnet filter, decease filter size and stride\n",
    "\n",
    "base_model_v2 = Sequential()\n",
    "base_model_v2.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v2.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v2.add(Conv2D(32, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "base_model_v2.add(Flatten())\n",
    "\n",
    "base_model_v2.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v2.add(Dropout(0.2))\n",
    "base_model_v2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model_v2.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model_v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 32/300 [==>...........................] - ETA: 3:28 - loss: 4.7879 - acc: 0.0012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a82f3488318f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m base_model_v2.fit_generator(train_generator, validation_data=validation_generator,\n\u001b[1;32m----> 2\u001b[1;33m                          steps_per_epoch=300, epochs=10, callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model_v2.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying a larger FC layer\n",
    "\n",
    "base_model_v3 = Sequential()\n",
    "base_model_v3.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v3.add(Conv2D(32, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "base_model_v3.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(Flatten())\n",
    "\n",
    "base_model_v3.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "base_model_v3.add(Dropout(0.2))\n",
    "base_model_v3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "adam_op = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model_v3.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(base_model_v3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 25, 25, 64)        55360     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               73984     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 259,768\n",
      "Trainable params: 259,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# trying deep_model architecture (in this case, adding additional conv layer and pooling after 2 conv +activation layers\n",
    "\n",
    "deep_model = Sequential()\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Conv2D(96, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Conv2D(64, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "deep_model.add(Flatten())\n",
    "\n",
    "deep_model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "deep_model.add(Dropout(0.2))\n",
    "deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "# use existing adam optimizer\n",
    "deep_model.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 4.7901 - acc: 0.0076 - val_loss: 4.7877 - val_acc: 0.0071\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.7890 - acc: 0.0063 - val_loss: 4.7873 - val_acc: 0.0063\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 150s 499ms/step - loss: 4.7874 - acc: 0.0072 - val_loss: 4.7871 - val_acc: 0.0121\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 155s 517ms/step - loss: 4.7895 - acc: 0.0064 - val_loss: 4.7872 - val_acc: 0.0071\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 156s 520ms/step - loss: 4.7877 - acc: 0.0085 - val_loss: 4.7871 - val_acc: 0.0079\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 153s 509ms/step - loss: 4.7875 - acc: 0.0091 - val_loss: 4.7870 - val_acc: 0.0088\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 4.7879 - acc: 0.0087 - val_loss: 4.7868 - val_acc: 0.0092\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7885 - acc: 0.0067 - val_loss: 4.7870 - val_acc: 0.0092\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 154s 513ms/step - loss: 4.7874 - acc: 0.0077 - val_loss: 4.7868 - val_acc: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a8e593860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=50, callbacks=[early_stopping])\n",
    "\n",
    "# not enough steps per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "800/800 [==============================] - 410s 512ms/step - loss: 4.7871 - acc: 0.0096 - val_loss: 4.7863 - val_acc: 0.0100\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 422s 527ms/step - loss: 4.7871 - acc: 0.0090 - val_loss: 4.7855 - val_acc: 0.0125\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 419s 524ms/step - loss: 4.7865 - acc: 0.0082 - val_loss: 4.7846 - val_acc: 0.0108\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 407s 509ms/step - loss: 4.7850 - acc: 0.0117 - val_loss: 4.7827 - val_acc: 0.0087\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 405s 506ms/step - loss: 4.7836 - acc: 0.0097 - val_loss: 4.7805 - val_acc: 0.0112\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 403s 504ms/step - loss: 4.7829 - acc: 0.0099 - val_loss: 4.7776 - val_acc: 0.0100\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 412s 515ms/step - loss: 4.7767 - acc: 0.0127 - val_loss: 4.7714 - val_acc: 0.0104\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 416s 519ms/step - loss: 4.7750 - acc: 0.0108 - val_loss: 4.7661 - val_acc: 0.0142\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 429s 536ms/step - loss: 4.7640 - acc: 0.0129 - val_loss: 4.7595 - val_acc: 0.0133\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 435s 543ms/step - loss: 4.7642 - acc: 0.0128 - val_loss: 4.7487 - val_acc: 0.0104\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 422s 528ms/step - loss: 4.7544 - acc: 0.0126 - val_loss: 4.7403 - val_acc: 0.0133\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 394s 492ms/step - loss: 4.7433 - acc: 0.0165 - val_loss: 4.7279 - val_acc: 0.0150\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 406s 507ms/step - loss: 4.7379 - acc: 0.0157 - val_loss: 4.7165 - val_acc: 0.0129\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 406s 508ms/step - loss: 4.7217 - acc: 0.0167 - val_loss: 4.7020 - val_acc: 0.0146\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 415s 518ms/step - loss: 4.7149 - acc: 0.0164 - val_loss: 4.6868 - val_acc: 0.0150\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 424s 530ms/step - loss: 4.7067 - acc: 0.0164 - val_loss: 4.6804 - val_acc: 0.0167\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 414s 517ms/step - loss: 4.6944 - acc: 0.0185 - val_loss: 4.6674 - val_acc: 0.0200\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 424s 530ms/step - loss: 4.6804 - acc: 0.0198 - val_loss: 4.6484 - val_acc: 0.0179\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 420s 525ms/step - loss: 4.6752 - acc: 0.0194 - val_loss: 4.6574 - val_acc: 0.0192\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 416s 520ms/step - loss: 4.6697 - acc: 0.0199 - val_loss: 4.6397 - val_acc: 0.0221\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 410s 512ms/step - loss: 4.6486 - acc: 0.0211 - val_loss: 4.6208 - val_acc: 0.0221\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 405s 507ms/step - loss: 4.6522 - acc: 0.0210 - val_loss: 4.6114 - val_acc: 0.0212\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 412s 515ms/step - loss: 4.6451 - acc: 0.0214 - val_loss: 4.6029 - val_acc: 0.0212\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 417s 521ms/step - loss: 4.6414 - acc: 0.0216 - val_loss: 4.5922 - val_acc: 0.0217\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 415s 519ms/step - loss: 4.6260 - acc: 0.0225 - val_loss: 4.5795 - val_acc: 0.0221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a93d4b5f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=800, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.save('deep_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_89 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 222, 222, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 109, 109, 32)      18464     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 52, 52, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               2367744   \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 2,428,088\n",
      "Trainable params: 2,428,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# old iteration\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(64, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_3.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_3.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model_3.add(Flatten())\n",
    "\n",
    "model_3.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "\n",
    "# Compile model\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work\n",
    "#model_3.fit_generator(train_generator, validation_data=validation_generator,\n",
    "#                    steps_per_epoch=300, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 1,434,936\n",
      "Trainable params: 1,434,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model_slow_learn = Sequential()\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_slow_learn.add(Conv2D(32, (3, 3), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_slow_learn.add(Flatten())\n",
    "\n",
    "wide_model_slow_learn.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_slow_learn.add(Dropout(0.2))\n",
    "wide_model_slow_learn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "\n",
    "adam_op = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "wide_model_slow_learn.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model_slow_learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 162s 540ms/step - loss: 4.8012 - acc: 0.0101 - val_loss: 4.7898 - val_acc: 0.0079\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 155s 516ms/step - loss: 4.7940 - acc: 0.0045 - val_loss: 4.7881 - val_acc: 0.0083\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 154s 512ms/step - loss: 4.7945 - acc: 0.0117 - val_loss: 4.7869 - val_acc: 0.0079\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 155s 517ms/step - loss: 4.7954 - acc: 0.0056 - val_loss: 4.7859 - val_acc: 0.0087\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 159s 528ms/step - loss: 4.7907 - acc: 0.0077 - val_loss: 4.7855 - val_acc: 0.0096\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 159s 530ms/step - loss: 4.7907 - acc: 0.0093 - val_loss: 4.7851 - val_acc: 0.0079\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 155s 517ms/step - loss: 4.7896 - acc: 0.0111 - val_loss: 4.7849 - val_acc: 0.0088\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 155s 516ms/step - loss: 4.7856 - acc: 0.0109 - val_loss: 4.7846 - val_acc: 0.0100\n",
      "Epoch 9/50\n",
      " 33/300 [==>...........................] - ETA: 1:29 - loss: 4.7907 - acc: 0.0036"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-83b203d9b42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m wide_model_slow_learn.fit_generator(train_generator, validation_data=validation_generator,\n\u001b[1;32m----> 2\u001b[1;33m                          steps_per_epoch=300, epochs=50, callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wide_model_slow_learn.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 1,434,936\n",
      "Trainable params: 1,434,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model_fast_learn = Sequential()\n",
    "wide_model_fast_learn.add(Conv2D(32, (3, 3), strides=1, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_fast_learn.add(Conv2D(32, (3, 3), strides=1, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "wide_model_fast_learn.add(Conv2D(32, (3, 3), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wide_model_fast_learn.add(Flatten())\n",
    "\n",
    "wide_model_fast_learn.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "wide_model_fast_learn.add(Dropout(0.2))\n",
    "wide_model_fast_learn.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "\n",
    "adam_op = Adam(lr=1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "wide_model_fast_learn.compile(loss='categorical_crossentropy', optimizer=adam_op, metrics=['accuracy'])\n",
    "print(wide_model_fast_learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 162s 541ms/step - loss: 15.9624 - acc: 0.0073 - val_loss: 15.9838 - val_acc: 0.0083\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 156s 519ms/step - loss: 15.9999 - acc: 0.0073 - val_loss: 15.9838 - val_acc: 0.0083\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 152s 506ms/step - loss: 16.0106 - acc: 0.0067 - val_loss: 15.9838 - val_acc: 0.0083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f934adb00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model_fast_learn.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                         steps_per_epoch=300, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
