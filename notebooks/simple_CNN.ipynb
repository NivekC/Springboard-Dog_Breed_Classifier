{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\garrick\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "seed = 16\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1475249643691004847\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1489587404\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 2680521960539963153\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#check using system GPU for processing\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare ImageDataGenerator and flow_from_directory vars\n",
    "batch_size=10\n",
    "num_classes = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing directory for flow_from_directory method\n",
    "os.chdir('C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain train and test labels\n",
    "from scipy.io import loadmat\n",
    "\n",
    "y_train_rough = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "\n",
    "y_test = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\test_list.mat''')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['labels']\n",
    "files = loadmat(r'''C:\\\\Users\\\\Garrick\\\\Documents\\\\Springboard\\\\Capstone Project 2\\\\datasets\\\\train_list.mat''')['file_list']\n",
    "labels = [item for label in labels for item in label] #this is flattening a list of lists, because for some reason ever label is stored as a list\n",
    "files = [item for file in files for item in file]\n",
    "df = pd.DataFrame({'labels':labels, 'files':files})\n",
    "train, validate = train_test_split(df, test_size = 0.2, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['files']\n",
    "y_train = to_categorical(train['labels'])\n",
    "X_val = validate['files']\n",
    "y_val = to_categorical(validate['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 images belonging to 120 classes.\n",
      "Found 2400 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15, shear_range=0.1, channel_shift_range=20,\n",
    "                                    width_shift_range=0.1,  height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True,\n",
    "                                    fill_mode='nearest', rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('validation', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('test', target_size=(224,224), color_mode='rgb',\n",
    "            class_mode='categorical', shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1bae7da4f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_validation = []\\ny_train = []\\n\\nfor i in range(120):\\n    i = i*100\\n    \\n    #begin_index = train_full_list[i::100]\\n    #end_index = train_full_list[i+100::100]\\n    \\n    slice = y_train_rough[i:i+100,]\\n    y_train.append(slice[:80])\\n    y_validation.append(slice[80:])\\n\\ny_train = np.concatenate(y_train, axis=0)\\ny_validation = np.concatenate(y_validation, axis=0)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain validation labels\n",
    "# no longer used, utilizing sklearn's train_test_split function\n",
    "\n",
    "'''\n",
    "y_validation = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(120):\n",
    "    i = i*100\n",
    "    \n",
    "    #begin_index = train_full_list[i::100]\n",
    "    #end_index = train_full_list[i+100::100]\n",
    "    \n",
    "    slice = y_train_rough[i:i+100,]\n",
    "    y_train.append(slice[:80])\n",
    "    y_validation.append(slice[80:])\n",
    "\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "y_validation = np.concatenate(y_validation, axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a simple CNN to start\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import keras.utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        32800     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 183,768\n",
      "Trainable params: 183,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224, 3)\n",
    "\n",
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (11, 11), strides=4, input_shape=input_shape, padding='valid', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (4, 4), strides=2, activation='relu', padding='valid', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "     \n",
    "\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.003\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure tensorflow before fitting model\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "# train/fit the simple CNN using flow from directory **********CURRENTLY CRASHING********\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 12000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    " \n",
    "#Load the VGG model\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=input_shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
